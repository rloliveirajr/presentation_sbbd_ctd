\section{Algorithms}

In this section we present novel selective sampling approaches for learning classifiers to distinguish between different sentiments expressed in Twitter messages. We start by discussing models based on specialized association rules.
Then we present measures for adaptiveness and memorability, and describe the message utility space. Finally, we discuss Pareto and Kaldor-Hicks criteria, and algorithms that select training messages using these criteria.

\subsection{Sentiment Stream Analysis}

In our context, the task of learning sentiment streams is precisely defined as follows. At time step $n$, we have as input
a training set referred to as $\mathcal{D}_n$, which consists of
a set of records of the form $<d,s_i>$, where $d$ is a
message (represented as a list of terms),
and $s_i$ is the sentiment implicit in $d$.
The sentiment variable $s$ draws its values from a pre-defined, fixed and discrete set of possibilities (e.g., $s_1$,
$s_2$, $\ldots$, $s_k$).
The training set is used to build a classifier relating textual patterns in the messages to their corresponding sentiments.
A sequence of future messages referred to as $\mathcal{T}=\{t_n, t_{n+1}, \ldots\}$, consists of messages
for which only their terms are known, while the corresponding sentiments are unknown.
The classifier obtained from $\mathcal{D}_n$ is used
to score the sentiments for message $t_n$ in $\mathcal{T}$.
Messages in $\mathcal{T}$ are eventually incorporated into the next training set.

There are countless strategies for devising
a classifier for sentiment analysis. Many of these strategies, however, are not well-suited to deal with data streams. Some are specifically devised for offline classification~\cite{trees,cortes}, and this is problematic because producing classifiers on-the-fly would be unacceptably costly. %Even updating the models in scenarios with high-speed streams would be
%excessively lengthy.
In such circumstances, alternate classification strategies may become more convenient~\cite{calibrated}.

\subsection{Sentiment Rules and Classifiers}

Next we describe classifiers composed of association rules, and how these rules are used for sentiment-scoring. Such classifiers are built on-the-fly~\cite{hipc,lac}, being thus well-suited for sentiment stream analysis, as shown in~\cite{sigir}.

\paragraph*{\bf{Definition 1}}
A sentiment rule is a specialized association rule $\mathcal{X}\xrightarrow{}s_i$, where the antecedent $\mathcal{X}$ is a set of terms (i.e., a termset), and the consequent $s_i$ is the predicted sentiment. The domain for $\mathcal{X}$ is the vocabulary of the training set $\mathcal{D}_n$.
The support of $\mathcal{X}$ is denoted as $\sigma(\mathcal{X})$, and is the number of messages in $\mathcal{D}_n$ having $\mathcal{X}$ as a subset. The confidence of rule $\mathcal{X}\xrightarrow{}s_i$ is denoted as $\theta(\mathcal{X}\xrightarrow{}s_i)$ and is given as $\displaystyle\frac{\sigma(\mathcal{X}\cup s_i)}{\sigma(\mathcal{X})}$.\\

\subsection*{Sentiment Scoring}

We denote as $\mathcal{R}(t_n)$ the classifier obtained at time step $n$, by extracting rules from $\mathcal{D}_n$.
Basically, the classifier is a poll of rules, and each rule $\{\mathcal{X}\xrightarrow{}s_i\}\in\mathcal{R}(t_n)$ is a vote given for sentiment $s_i$. Given message $t_n$, a rule is a valid vote if it is applicable to $t_n$.

\paragraph*{\bf{Definition 2}} A rule $\{\mathcal{X}\xrightarrow{}s_i\}\in\mathcal{R}(t_n)$ is said to be applicable to message $t_n\in\mathcal{T}$ if
all terms in $\mathcal{X}$ are in $t_n$.\\

We denote as $\mathcal{R}_a(t_n)$ the set of rules in $\mathcal{R}(t_n)$ that are applicable to message $t_n$. Thus, only rules in $\mathcal{R}_a(t_n)$ are considered as valid votes when scoring sentiments in $t_n$.
Further, we denote as $\mathcal{R}^{s_i}_a(t_n)$ the subset of $\mathcal{R}(t_n)$ containing only rules predicting sentiment $s_i$.
Votes in $\mathcal{R}^{s_i}_a(t_n)$ have different weights, depending on the confidence of the corresponding rules. The weighted votes for sentiment $s_i$ are averaged, giving the score for $s_i$ with regard to $t_n$:

\begin{equation} \label{eq1}
s(t_n, s_i)=\displaystyle\sum \displaystyle\frac{\theta(\mathcal{X}\xrightarrow{}s_i)}{|\mathcal{R}^{s_i}_a(t_n)|}
\end{equation}

Finally, the scores are normalized, thus giving the likelihood of sentiment $s_i$ being the attitude in message $t_n$:

\begin{equation}
\label{eq:prob}
\hat{p}(s_i|t_n)=\displaystyle\frac{s(t_n, s_i)}{\displaystyle\sum^{k}_{j=1} s(t_n, s_j)}
\end{equation}

\subsection*{Rule Extraction}

The simplest approach to rule extraction is the offline one. In this case, rule extraction is divided into two steps: support counting and confidence computation. Once the support $\sigma(\mathcal{X})$ is known, it is straightforward to compute the confidence $\theta(\mathcal{X}\xrightarrow{}s_i)$ for the corresponding rules~\cite{eclat}.
There are several smart support-counting strategies~\cite{rules,fp,eclat}, and many fast implementations~\cite{fimi} that can be used.
We employ the vertical counting strategy, which is based on the use of inverted lists~\cite{vertical}.
Specifically, an inverted list associated with termset $\mathcal{X}$, is denoted as $\mathcal{L}(\mathcal{X})$, and contains the identifiers of the messages in $\mathcal{D}_n$ having termset $\mathcal{X}$ as a subset. An inverted list $\mathcal{L}(\mathcal{X})$ is obtained by performing the intersection of two proper subsets of termset $\mathcal{X}$. The support of termset $\mathcal{X}$ is given by the cardinality of $\mathcal{L}(\mathcal{X})$, that is, $\sigma(\mathcal{X})=|\mathcal{L}(\mathcal{X})|$.

Usually, the support for different sets of terms in $\mathcal{D}_n$ are computed in a bottom-up way, which
starts by scanning all messages in $\mathcal{D}_n$
and computing the support of each term in isolation.
In the next iteration,
pairs of terms are enumerated, and their support values are calculated by performing the intersection of the corresponding proper subsets.
The search for sets of terms proceeds, and the enumeration process is repeated until the support values for all sets of terms in $\mathcal{D}_n$ are finally computed.
Obviously, the number of rules increases exponentially with the size of the vocabulary (i.e., the number of distinct terms in $\mathcal{D}_n$), and
computational cost restrictions have to be imposed during
rule extraction. Typically, the search space for rules is restricted by pruning
rules that do not appear frequently in $\mathcal{D}_n$ (i.e., the minimum support approach). While such restrictions make rule extraction feasible, they also lead to lossy classifiers, since some rules are pruned and therefore are not included into $\mathcal{R}(t_n)$.

\paragraph*{\bf{Online Rule Extraction}}
An alternative to offline rule extraction is to extract rules on-the-fly. Such alternative, which we call online rule extraction, has several advantages~\cite{sigir}. For instance, it becomes possible to efficiently extract rules from $\mathcal{D}_n$ without performing support-based pruning.
The idea behind online rule extraction is to ensure that only applicable rules are extracted by projecting $\mathcal{D}_n$ on a demand-driven basis. More specifically, rule extraction is delayed until a message $t_n\in\mathcal{T}$ is given. Then, terms in $t_n$ are used as a filter which configures $\mathcal{D}_n$ in a way that only rules that are applicable to $t_n$ can be extracted. This filtering process produces a projected training-set, denoted as $\mathcal{D}^{*}_n$, which contains only terms that are present in message $t_n$.

\paragraph*{\bf{Lemma 1}}
All rules extracted from $\mathcal{D}^{*}_n$ are applicable to $t_n$.

\paragraph*{\bf{Proof}}
Since all training messages in $\mathcal{D}^{*}_n$ contain only terms that are
present in message $t_n$, the existence of a rule
$\mathcal{X}\xrightarrow{}s_i$ extracted from $\mathcal{D}^{*}_n$, such that
$\mathcal{X}\nsubseteq t_n$, is impossible. $\blacksquare$\\

Lemma 1 implies that online rule extraction assures that $\mathcal{R}(t_n)=\mathcal{R}_a(t_n)$.
The next theorem states that
search space for rules induced by $\mathcal{D}^{*}_n$ is much narrower than the search space for rules induced by $\mathcal{D}_n$. Thus, rules
can be efficiently extracted from $\mathcal{D}^{*}_n$, no matter the minimum-support value (which can be arbitrary low).

\paragraph*{\bf{Theorem 1}}
The number of rules extracted from $\mathcal{D}^{*}_n$ increases polynomially with
the number of distinct terms in $\mathcal{D}_n$.

\paragraph*{\bf{Proof}}
Let $k$ be the number of distinct terms in
$\mathcal{D}_n$.
Since an arbitrary message $t_n\in\mathcal{T}$ contains at most $l$
terms (with $l\ll k$), then any rule applicable to $t_n$
can have at most $l$ terms in its antecedent. That is, for any
rule $\{\mathcal{X}\xrightarrow{}s_i\}$, such that $\mathcal{X}\subseteq t_n$,
$|\mathcal{X}|\le l$. Consequently, the number of
possible rules that are applicable to $t_n$ is
$l+{{l}\choose{2}}+\ldots+{{l}\choose{l}}=O(2^l)\ll O(k^l)$.
Thus, the number of applicable rules increases
polynomially in $k$.
$\blacksquare$\\

\paragraph*{\bf{Extending Classifiers Dynamically}}
Let $\mathcal{R}=\{\mathcal{R}(t_1)\cup\mathcal{R}(t_2)$ $\cup\ldots\cup\mathcal{R}(t_n)\}$.
With online rule extraction, 
$\mathcal{R}$ is extended dynamically as messages $t_i\in\mathcal{T}$ are processed. Initially $\mathcal{R}$ is empty; a classifier $\mathcal{R}_{t_i}$ is appended to $\mathcal{R}$ every time a message $t_i$ is processed.
Producing a classifier $\mathcal{R}(t_i)$ involves extracting rules from the corresponding training-set. This operation has a significant computational cost, since it is necessary perform multiple accesses to $\mathcal{D}_i$.
Different messages in $\mathcal{T}=\{t_1, t_2, \ldots, t_m\}$ may demand different classifiers $\{\mathcal{R}_{t_1}, \mathcal{R}_{t_2}, \ldots,$ $\mathcal{R}_{t_m}\}$,
but different classifiers may share some rules (i.e., $\{\mathcal{R}_{t_i}\cap\mathcal{R}_{t_j}\}\ne\emptyset$).
In this case,
memorization is very effective in avoiding work replication,
reducing the number of data access operations.
Thus, before extracting
rule $\mathcal{X}\xrightarrow{}s_i$, the classifier first checks whether this rule is
already in $\mathcal{R}$. If an entry is found, then the rule
in $\mathcal{R}$ is used instead of extracting it from the training-set. If it is not found, the rule is
extracted from the training-set and then it is inserted into $\mathcal{R}$.

%\paragraph*{\bf{Model Maintenance}}
%Rules in $\mathcal{R}$ may become invalid when reliable labeled messages $<t, s_i>$ are included into $\mathcal{D}$. As a result,
%$\mathcal{R}$ has to be updated properly. We propose to maintain the model up-to-date incrementally, so that the updated model is exactly the same one that
%would be obtained by re-constructing it from scratch.
%
%Update speed is a key issue in model maintenance, and a challenge that threatens the efficiency of our approach is that the model may be composed of a potentially large number of rules, and updating all these rules may be unacceptably costly in a streaming environment.
%Fortunately, not all rules in $\mathcal{R}$ have to be updated.
%
%\paragraph*{Lemma 2} The inclusion of a labeled message $<t, s_i>$ into $\mathcal{D}$ does not change the value of $\sigma(\mathcal{X})$, for any termset $\mathcal{X}\not\subset t$.
%
%\paragraph*{Proof} Since $\mathcal{X}\not\subset t$, the number of messages in $\mathcal{D}$ having $\mathcal{X}$ as a subset is essentially the same as in $\{\mathcal{D}\cup t\}$. $\blacksquare$
%
%\paragraph*{Lemma 3} The inclusion of a labeled message $<t, s_i>$ into $\mathcal{D}$ does not change the value of $\theta(\mathcal{X}\xrightarrow{}s)$,
%for any rule $\{\mathcal{X}\xrightarrow{}s\}\in\mathcal{R}$ for which $\mathcal{X}\not\subset t$,
%$\forall s\in\{s_1, s_2,\ldots, s_k\}$.
%
%\paragraph*{Proof} Comes directly from the fact that confidence is invariant under the null-addition operation~\cite{measure1}.
%$\blacksquare$\\
%
%From Lemmas 2 and 3, the number of rules that have to be updated due to the inclusion of labeled message $<t, s_i>$, is bounded by the number of possible termsets in $t$. Since most of the messages that are included into $\mathcal{D}$ contain only a very small fraction of all possible termsets, the inclusion of an arbitrary message $t$ corresponds to a null-addition to most of the rules in $\mathcal{R}$. The following lemma states exactly the rules in $\mathcal{R}$ that have to be updated.
%
%\paragraph*{Lemma 4} The only and all the rules in $\mathcal{R}$ that must be updated due to the inclusion of labeled message $<t, s_i>$ are those in $\mathcal{R}_t$.
%
%\paragraph*{Proof} All rules $\{\mathcal{X}\xrightarrow{}s_i\}\in\mathcal{R}$ that have to be updated due to the inclusion of $<t, s_i>$ are those for which $\mathcal{X}\subseteq t$. By definition, $\mathcal{R}_t$ contains only and all such rules. $\blacksquare$\\
%
%Once rules 
%$\{\mathcal{X}\xrightarrow{}s\}\in\mathcal{R}_t$ are retrieved from $\mathcal{R}$,
%updating the corresponding values for $\sigma(\mathcal{X})$ and $\theta(\mathcal{X}\xrightarrow{}s)$
% is a simple operation. It suffices to iterate on $\mathcal{R}_t$ and increment the values of $\sigma(\mathcal{X})$ and $\sigma(\mathcal{X}\cup s)$. The corresponding values for $\theta(\mathcal{X}\xrightarrow{}s)$
%are obtained by computing $\frac{\sigma(\mathcal{X}\cup s)}{\sigma(\mathcal{X})}$
%$\forall s\in\{s_1, s_2, \ldots, s_k\}$.

\subsection{Utility Space and Selective Sampling}

Our approach to sentiment stream analysis is based on selecting high-utility messages to compose the training set at each time step. Training sets must provide adaptiveness and memorability to the corresponding classifiers. Improving adaptiveness and memorability simultaneously, however, is a conflicting-objective problem. Instead, our approaches create training sets that balance between adaptiveness and memorability. Specifically, at each time step, candidate messages are placed into an n-dimensional space, in which each dimension corresponds to a utility measure which is either related to adaptiveness or memorability.

\subsection*{Utility Measures}
%\paragraph*{\bf{Utility Measures}}
At each time step, the classifier must score sentiments that are expressed in the target message. Some of the utility measures we are going to discuss next are based on the distance to the target message. By minimizing such distance we are essentially maximizing adaptiveness, since the selected messages are similar to the target message. As for memorability, we are going to discuss a utility measure based on randomly shuffling candidate messages:

\begin{itemize}
\item{\bf{Distance in space} $-$}
The similarity between the target message $t_n$ and an arbitrary message $t_j$ is given by the number of rules in the classifier $\mathcal{R}_a(t_n)$ that are also applicable to $t_j$.
Differently from traditional measures such as cosine and Jaccard~\cite{baeza99modern}, the rule-based similarity considers not only isolated terms, but also combination of terms.
Thus, the utility of message $t_j$ is given as:

\begin{equation}
%U_s(t_j)=\displaystyle\frac{|\{r\in\mathcal{R}_a(t_n)\mbox{ such that }r\mbox{ is applicable to }t_j\}|}{|\{\mathcal{R}_a(t_n)\}|}
U_s(t_j)=\displaystyle\frac{|\mathcal{R}_a(t_n)\cap\mathcal{R}_a(t_j)|}{|\{\mathcal{R}_a(t_n)\}|}
\end{equation}

\item{\bf{Distance in time} $-$}
Let $\gamma(t_j)$ be a function that returns the time in which message $t_j$ arrived. The utility of message $t_j$ is given as: 

\begin{equation}
U_t(t_j)=\displaystyle\frac{\gamma(t_j)}{\gamma(t_n)}
\end{equation}

\item{\bf{Memorability} $-$}
In order to provide memorability, the training set must contain messages posted in different time periods. A simple way to force this is to generate a random permutation of the candidate messages, that is, randomly shuffling the candidate messages~\cite{permutation}.
Let $\alpha(t_j)$ be a function that returns the position of message $t_j$ in the shuffle.
The utility of message $t_j$ is given as:

\begin{equation}
U_r(t_j)=\frac{\alpha(t_j)}{|\mathcal{D}_n|}
\end{equation}



\end{itemize}

Each candidate message is judged based on these three utility measures. The need to judge one situation better than another motivates much of Economics, and next we discuss concepts from Economics and how they can be applied to select messages to compose the training set.

\input{t}

\subsection{Economic Efficiency}

When the society is economically efficient, any changes made to assist one person would harm another. The same intuition could be exploited for the sake of selecting messages to compose the training set at each time step. In this case, a training set is economically efficient if it is only possible to improve memorability at the cost of adaptiveness, and vice-versa~\cite{recsys12,icmr14}.

There is an alternative, less stringent notion of efficiency, which is based on the principle of compensation~\cite{compensation}.
Under new arrangements in the society, some may be better off while others may be worse off.
Compensation holds if those made better off
under the new set of conditions could compensate those made worse off. Next we discuss algorithms that exploit these two notions of economic efficiency in order to select messages to compose the training sets.

\subsection*{Pareto Frontier}
%\paragraph*{\bf{Pareto Frontier}}
Messages that are candidate to compose the training set at time step $n$ are placed in a 3-dimensional space, according to their utility measures, as shown in Figure~\ref{fig:ex1}.
Thus, each message $a$ is a point in such utility space, and is given as $<U_s(a),U_t(a),U_r(a)>$.

\paragraph*{\bf{Definition 3}} Message $a$ is said to dominate message $b$ iff both of the following conditions are hold:
\begin{itemize}
\item $U_s(a)\ge U_s(b)$ and $U_t(a)\ge U_t(b)$ and $U_r(a)\ge U_r(b)$
\item $U_s(a) > U_s(b)$ or $U_t(a) > U_t(b)$ or $U_r(a) > U_r(b)$
\end{itemize}
Therefore, the dominance operator relates two messages so that the result of the
operation has two possibilities as shown in Figure~\ref{fig:ex2} (Left): (i) one message dominates another or (ii) the two
messages do not dominate each other.

\input{tt}

\paragraph*{\bf{Definition 4}} Training set $\mathcal{P}_n=\{d_1, d_2, \ldots, d_m\}$ is said to be Pareto-efficient at time step $n$, if $\mathcal{P}_n\subseteq\mathcal{D}_n$ and there is no pair of messages $(d_i, d_j)\in\mathcal{P}_n$ for which $d_i$ dominates $d_j$.\\

Messages that are not dominated
by any other message, lie on the Pareto frontier~\cite{palda@book}. Therefore, by definition, the Pareto-efficient training set at time step $n$, $\mathcal{P}_n$, is composed by all the messages lying in the Pareto frontier that is built from $\mathcal{D}_n$.
There are efficient algorithms for building and maintaining the Pareto frontier, and we employed the algorithm proposed in~\cite{operator} which ensures $O$($|\mathcal{D}_n|$) complexity.
%Finally, dominated messages are discarded from $\mathcal{D}_n$, since for each dominated message there is at least one message in $\mathcal{P}_n$ that beats it in at least one utility measure.
We denote the process of exploiting Pareto-efficient training sets as
Pareto-Efficient Selective Sampling, or simply PESS. Figure~\ref{fig:ex2} (Middle) shows an illustrative example of a Pareto frontier built from arbitrary points in the utility space.
%These messages are likely to offer a good balance between adaptiveness and memorability.

\subsection*{Kaldor-Hicks Region}
%\paragraph*{\bf{Kaldor-Hicks Region}}
The PESS strategy follows a stringent criterion, which tends to select only few messages to compose the training sets. As a result, the training sets may become excessively small and prone to noise.
The Kaldor-Hicks criterion, on the other hand,
follows a cost-benefit analysis and circumvents the
small training set problem by stating that efficiency is achieved if
those that are made better off could in theory compensate those that are made worse off. Thus, under the Kaldor-Hicks criterion, an utility measure can compensate other utility measures, and therefore, this criterion selects messages that are located inside a region which is below the Pareto frontier. To define this region we must first define the overall utility of a message.

\paragraph*{\bf{Definition 5}} Assuming that all measures are equally important, the overall utility of an arbitrary message $d_i\in\mathcal{D}_n$ is:

\begin{equation}
\label{eq:cost}
%\nonumber
U(d_i)=U_s(d_i)+U_t(d_i)+U_r(d_i)
\end{equation}

\noindent That is, the overall utility of a message is given as the sum of its utility measures. Also, the baseline message, which is denoted as $d^*$, is defined as:

\begin{equation}
%\nonumber
d^*=\{d_i\in\mathcal{P}_n | \forall d_j\in\mathcal{P}_n: U(d_i)\leq U(d_j)\}
\end{equation}

\noindent That is, the baseline is the message lying in the frontier for which the overall utility assumes its lowest value.\\

The Kaldor-Hicks region is composed of messages for which the overall utility is not smaller than the baseline overall utility. Such baseline utility is the utility associated with the message lying in the Pareto frontier for which the overall utility is the lowest.

%\begin{algorithm}[t!]
%  \caption{\textbf{Pareto-Efficient Selective Sampling}}
%  \label{alg:pareto}
%  \begin{algorithmic}[1]
%    \Require Messages in $\mathcal{D}_n$
%    \Statex
%    \State $\mathcal{P}_n \gets \emptyset$
%    \ForAll {messages $d \in \mathcal{D}_n$}
%        \State $notDominated \gets True$
%        \ForAll {messages $p \in \mathcal{P}_n$}
%            \If{$d$ dominates $p$}
%                  \State Remove $p$ from $\mathcal{P}_n$
%                \ElsIf{$p$ dominates $d$}
%              \State insert $p$ into $\mathcal{P}_n$
%                  \State $notDominated \gets False$
%                  \State $break$
%                \EndIf
%        \EndFor
%        \If{$notDominated$}
%                \State insert $d$ into $\mathcal{P}_n$
%        \EndIf
%    \EndFor
%    \State $\mathcal{D}_n \gets \mathcal{P}_n$
%    \State \textbf{return} $\mathcal{P}_n$
%  \end{algorithmic}
%\end{algorithm}

\paragraph*{\bf{Definition 6}} Training set $\mathcal{K}_n=\{d_1, d_2, \ldots, d_m\}$ is said to be Kaldor-Hicks-efficient at time step $n$, if $\mathcal{P}_n\subseteq\mathcal{K}_n\subseteq\mathcal{D}_n$, and there is no message $d_i\in\mathcal{K}_n$ such that $U(d^*)>U(d_i)$.\\

We denote the process of exploiting Kaldor-Hicks-efficient training sets as
Kaldor-Hicks-Efficient Selective Sampling, or simply KHSS. Figure~\ref{fig:ex2} (Right) shows an illustrative example of a Kaldor-Hicks region built from arbitrary points in the utility space.

%\begin{algorithm}[t!]
%  \caption{\textbf{Kaldor-Hicks-Efficient Selective Sampling}}
%  \label{alg:kh}
%  \begin{algorithmic}[1]
%    \Require Messages in $\mathcal{D}_n$ and messages in $\mathcal{P}_n$
%    \Statex
%
%    \State $\mathcal{K}_n \gets \emptyset$
%    %\State $min \gets \infty$
%    %\ForAll{messages $p \in \mathcal{P}_n$}
%    %    \State $k \gets U_s(p)+U_t(p)+U_r(p)$
%    %    \If{$k < min$}
%    %        \State $min \gets k$
%    %    \EndIf
%    %\EndFor
%    \State $d^* \gets \{d_i\in\mathcal{P}_n | \forall d_j\in\mathcal{P}_n: U(d_i)\leq U(d_j)\}$
%
%    \ForAll{messages $d \in \{\mathcal{D}_n-\mathcal{P}_n\}$}
%        %\State $q \gets U_s(d)+U_t(d)+U_r(d)$
%        %\If{$q \geq min$}
%        \If{$U(d) \geq U(d^*)$}
%            \State insert $d$ into $\mathcal{K}_n$
%        \EndIf
%    \EndFor
%    \State $\mathcal{D}_n \gets \mathcal{K}_n$
%    \State \textbf{return} $\mathcal{K}_n$
%  \end{algorithmic}
%\end{algorithm}
